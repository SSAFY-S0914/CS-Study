# 9주차 질문 목록

## ❓ 김선형
1. page size를 감소시키면 어캐됨?
    
    → 페이지 수 증가
    
    → 페이지 테이블 크기 증가
    
    → 내부 조각 감소
    
    → disk transfer의 효율성 감소
    
    → 필요한 정보만 메모리에 올라와 메모리 이용에 효율적
    
    → locality의 활용 측면에서는 좋지 않음
    
2. FIFO의 단점? 메모리 크기 (frame의 수) 크면 클수록, page fault가 더 늘어남 ⇒ FIFO Anomaly
3. 캐슁이란? 한정된 빠른 공간(캐쉬)에 요청된 데이터를 저장해놓고, 똑같은 데이터를 요청하게 되면 저장 메모리(디스크 등)까지 가지 않고, 캐쉬에서 바로 서비스를 제공 → 빠름
4. clock algorithm의 동작 과정? reference bit이 1이라면, 쫓아내진 않고, bit를 0으로 다시 셋팅하고 다음 페이지로 circular 이동 (reference bit이 0이라면 한 바퀴를 돌 때까지 한번도 참조를 하지 않았다는 뜻 → replace)
5. thrashing이란? 프로그램에 메모리가 너무 적게 할당되서 page fault가 지나치게 자주 일어나는 상황

## ❓ 박소민
1. page fault trap 발생 및 실행  과정
2. FIFO Anomaly란?
3. Second-Chance Algorithm(Clock Algorithm)이란?
4. Global Replacement 와 Local Replacement 차이
5. Thrashing 

## ❓ 배미혜


## ❓ 유승아

1. 요청한 페이지가 메모리에 없는 경우를 지칭하는 용어는
2. clock algorithm에서 어떤 bit를 사용하여 교체 대상 페이지를 선정하는가?
3. 위 문제의 bit와 함께 clock algorithm을 개선하기 위해 사용하는 다른 bit는 무엇이고 용도는 무엇인가?
4. LRU와 LFU의 시간 복잡도는?
5. CPU가 요청한 페이지가 메모리에 없을 때, 메모리에 free frame이 없을 경우 일어나는 일은?

## ❓ 이남곤

1. demand paging의 방식은?
2. FIFO anomaly란?
3. LRU, LFU 알고리즘에 대한 설명
4. clock 알고리즘의 동작 방식은?
5. thrashing에 대한 설명

## ❓ 이예은

1. 가상 메모리의 page fault 등 관리 주체는 누구인가? 그렇다면 가상 메모리가 아닌 메모리의 주소 변환은 누가(무엇이) 관리하는가?
2. LRU가 불리할 수 있는 상황을 예시로 드시오.
3. LFU가 불리할 수 있는 상황을 예시로 드시오.
4. LFU의 시간 복잡도는?
5. 주소 변환을 위해 사용하는 cache 의 이름은?
6. 가상 메모리 환경에서 Page fault가 발생하는 과정에 대해 자세히 설명하라 
(TLB miss → PT miss→ disk에서 swap in)
7. 가상 메모리 환경에서 hit가 발생하는 과정에 대해 자세히 설명하라 
(TLB hit→ cache hit→ 찾음)
8. memory reference가 발생한 page에 대해 쓰기 연산이 있었다면 해당 사항을 표시하는 bit의 이름은?
→ modified bit, dirty bit


## ❓ 이채림
